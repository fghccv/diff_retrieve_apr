{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "from transformers import AutoTokenizer\n",
    "model_name = \"/home/zhoushiqi/workplace/model/deepseek-coder-6.7b-instruct\"  # 你可以换成任何Hugging Face模型名称\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "datasets = utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/megadiff-single-function/process.jsonl\")\n",
    "corpus = [data['diff_context'] for data in datasets]\n",
    "tokenize_corpus = [data['tokenize_diff_context'] for data in datasets]\n",
    "\n",
    "\n",
    "bm25 = BM25Okapi(tokenize_corpus)\n",
    "\n",
    "buggy = utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/df4_process_data/one_function/1.2.jsonl\")\n",
    "answer = utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/evaluate_results/deepseek/baseline_1.2_N100_T1_process.jsonl\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    public void atan2(final double[] y, final int yOffset,\\n                      final double[] x, final int xOffset,\\n                      final double[] result, final int resultOffset) {\\n\\n        // compute r = sqrt(x^2+y^2)\\n        double[] tmp1 = new double[getSize()];\\n        multiply(x, xOffset, x, xOffset, tmp1, 0);      // x^2\\n        double[] tmp2 = new double[getSize()];\\n        multiply(y, yOffset, y, yOffset, tmp2, 0);      // y^2\\n        add(tmp1, 0, tmp2, 0, tmp2, 0);                 // x^2 + y^2\\n        rootN(tmp2, 0, 2, tmp1, 0);                     // r = sqrt(x^2 + y^2)\\n\\n        if (x[xOffset] >= 0) {\\n\\n            // compute atan2(y, x) = 2 atan(y / (r + x))\\n            add(tmp1, 0, x, xOffset, tmp2, 0);          // r + x\\n            divide(y, yOffset, tmp2, 0, tmp1, 0);       // y /(r + x)\\n            atan(tmp1, 0, tmp2, 0);                     // atan(y / (r + x))\\n            for (int i = 0; i < tmp2.length; ++i) {\\n                result[resultOffset + i] = 2 * tmp2[i]; // 2 * atan(y / (r + x))\\n            }\\n\\n        } else {\\n\\n            // compute atan2(y, x) = +/- pi - 2 atan(y / (r - x))\\n            subtract(tmp1, 0, x, xOffset, tmp2, 0);     // r - x\\n            divide(y, yOffset, tmp2, 0, tmp1, 0);       // y /(r - x)\\n            atan(tmp1, 0, tmp2, 0);                     // atan(y / (r - x))\\n            result[resultOffset] =\\n                    ((tmp2[0] <= 0) ? -FastMath.PI : FastMath.PI) - 2 * tmp2[0]; // +/-pi - 2 * atan(y / (r - x))\\n            for (int i = 1; i < tmp2.length; ++i) {\\n                result[resultOffset + i] = -2 * tmp2[i]; // +/-pi - 2 * atan(y / (r - x))\\n            }\\n\\n        }\\n\\n        // fix value to take special cases (+0/+0, +0/-0, -0/+0, -0/-0, +/-infinity) correctly\\n\\n    }\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[b1['project'] + '_' + str(b1['bug_id'])][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [28:53<00:00, 17.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import tqdm\n",
    "bug_id = 0\n",
    "all_retrieval = defaultdict(int)\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    fix_id = i\n",
    "    b1 = buggy[bug_id]\n",
    "    a1 = answer[b1['project'] + '_' + str(b1['bug_id'])][fix_id]\n",
    "    data = {'buggy_function':b1['erro_repairs'][0]['src_code'][0], 'fixed_function':a1.strip('\\n')}\n",
    "    query = utils._process(data, 3)\n",
    "    tokenized_query = tokenizer.tokenize(query)\n",
    "    retrive = bm25.get_top_n(tokenized_query, corpus, n=10)\n",
    "    for r in retrive:\n",
    "        all_retrieval[r] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = sorted(all_retrieval, key=lambda x:all_retrieval[x], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "from transformers import AutoTokenizer\n",
    "model_name = \"/home/zhoushiqi/workplace/model/deepseek-coder-6.7b-instruct\"  # 你可以换成任何Hugging Face模型名称\n",
    "\n",
    "# 加载tokenizerfrom gensim_bm25 import bm25\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "datasets = utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/megadiff-single-function/process.jsonl\")\n",
    "documents = [data['buggy_function'] for data in datasets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m new_datasets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mdatasets\u001b[49m):\n\u001b[1;32m      5\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      6\u001b[0m     b \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuggy_function\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "new_datasets = []\n",
    "index = 0\n",
    "for data in tqdm(datasets):\n",
    "    new_data = {}\n",
    "    b = data[\"buggy_function\"]\n",
    "    b = b.strip()\n",
    "    b = b.replace('\\t', '    ')\n",
    "    tokenized_buggy_code = tokenizer.tokenize(b)\n",
    "    if len(tokenized_buggy_code) > 10000:\n",
    "        continue\n",
    "    f = data[\"fixed_function\"]\n",
    "    f = f.strip()\n",
    "    f = f.replace('\\t', '    ')\n",
    "    tokenized_fixed_code = tokenizer.tokenize(f)\n",
    "    new_data['buggy_function'] = b\n",
    "    new_data['fixed_function'] = f\n",
    "    new_data['diff_context'] = data[\"diff_context\"]\n",
    "    new_data['tokenized_diff_context'] = data[\"tokenize_diff_context\"]\n",
    "    new_data['tokenized_buggy_function'] = tokenized_buggy_code\n",
    "    new_data['tokenized_fixed_function'] = tokenized_fixed_code\n",
    "    new_datasets.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.write_jsonl(\"/home/zhoushiqi/workplace/apr/data/megadiff-single-function/process.jsonl\", new_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "buggy = utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/df4_process_data/one_function/1.2.jsonl\")\n",
    "answer = utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/evaluate_results/deepseek/retrieval/baseline_1.2_OnlyBuggycode_N100_T1_process.jsonl\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:13<00:00, 18.41it/s]\n"
     ]
    }
   ],
   "source": [
    "diff_datas = []\n",
    "for bug in tqdm.tqdm(buggy):\n",
    "    new_data = {}\n",
    "    bug_id = f\"{bug['project']}_{bug['bug_id']}\"\n",
    "    if bug_id in plausible_ids or bug_id not in answer:\n",
    "        continue\n",
    "    buggy_code = bug['erro_repairs'][0]['src_code'][0].strip()\n",
    "    new_data['project'] = bug['project']\n",
    "    new_data['bug_id'] = bug['bug_id']\n",
    "    new_data['buggy_code'] = buggy_code\n",
    "    new_data['fixed'] = [a.strip() for a in answer[bug_id]]\n",
    "    new_data['diffs'] = [utils._process({'buggy_function':buggy_code, 'fixed_function':a}, 3) for a in new_data['fixed']]\n",
    "    diff_datas.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "x = json.load(open(\"/home/zhoushiqi/workplace/minicpm/MiniCPM/finetune/data/AdvertiseGen/all.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "# y1 = utils.read_jsonl(\"/home/guochuanzhe/share/math_sft/MathInstruct/MathInstruct.jsonl\")\n",
    "# y2 = utils.read_jsonl(\"/home/guochuanzhe/share/math_sft/MetaMathQA/MetaMathQA.jsonl\")\n",
    "y3 = utils.read_jsonl(\"/home/guochuanzhe/share/math_sft/orca-math-word-problems-200k/orca-math-word-problems-200k.jsonl\")\n",
    "# y4 = utils.read_jsonl(\"/home/guochuanzhe/share/math_sft/reasoningdata_200k-sharegpt/reasoningdata_200k-sharegpt.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "add = random.sample(y3, k=len(x)*2//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x += add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(x, open(\"/home/zhoushiqi/workplace/minicpm/MiniCPM/finetune/data/AdvertiseGen/all_add_math_8&2.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(x, open(\"/home/zhoushiqi/workplace/minicpm/MiniCPM/finetune/data/AdvertiseGen/all_add_math.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "len(utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/evaluate_results/deepseek/retrieval/baseline_1.2_random_N200_T1_process.jsonl\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9710257  0.99999994]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.similarities.docsim import MatrixSimilarity\n",
    "# 创建一些简单的文档向量\n",
    "documents_vectors = [[(0,0.121),(1,0.2)],[(0,0.2),(1,0.2)]]\n",
    "\n",
    "# 创建相似度索引\n",
    "index = MatrixSimilarity(documents_vectors, num_features=2)\n",
    "\n",
    "# 创建一个简单的查询向量\n",
    "query_vector = [(0,0.1),(1,0.1)]\n",
    "\n",
    "# 执行查询\n",
    "sims = index[query_vector]\n",
    "\n",
    "# 输出查询结果\n",
    "print(sims)\n",
    "index.save(\"temp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "for i,x in enumerate(utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/megadiff-single-function/process_filtered2048.jsonl\")):\n",
    "    assert i == x['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "x = utils.read_jsonl(\"/home/zhoushiqi/workplace/apr/data/evaluate_results/deepseek/retrieval/baseline_1.2_diff_vec_k2_N100_T1_result.jsonl\")\n",
    "t = 0\n",
    "for xx in x:\n",
    "    if \"Failing tests: 0\\n\" in xx['result'][:100]:\n",
    "        t += 1\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "y = json.load(open(\"/home/zhoushiqi/workplace/apr/data/evaluate_results/deepseek/retrieval/baseline_1.2_diff_vec_k1_N100_T1_process.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yy in y.values():\n",
    "    if '' in yy:\n",
    "        print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Closure_128', 'Closure_2'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y.keys())-(set(all) - set(plausible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = set(plausible).intersection(set(x_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lang_43'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all) - (set(x_k)-other).union(set(plausible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {\"project\": \"Lang\", \"bug_id\": 43, \"result\": [\"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\", \"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\", \"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\", \"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\", \"Compile Failing\", \"Compile Failing\", \"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\", \"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\", \"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\", \"Failing tests: 1\\n  - org.apache.commons.lang.text.ExtendedMessageFormatTest::testEscapedQuote_LANG_477\\n\"]}\n",
    "len(m['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
